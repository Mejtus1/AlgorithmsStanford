// --------------------------------------------------------------------------------------------------------
1. Introduction to Algorithms 
- algorithm is a step by step procedure of solving computational problem 
- program is also a step by step procedure of solving a problem 
- SDLC = software development lifecycle 
Algorithm                     Program 
Deisgn phase of SDLC          Implementation phase of SDLC 
Domain knowledge              Programmer (programmer can also have domain knowledge)
any language                  programming language 
(or mathematical notation)
Hardware/Software/OS          H/S/OS dependent 
idependent 
Analyze                       Testing 

// --------------------------------------------------------------------------------------------------------
1.1 Priori analysis, Postpriori testing 

Priori Analysis             Posteriori Testing
1. Algorithm                1. Program
2. Independent Language     2. Language dependent 
3. Hardware Independent     3. Hardware dependent 
4. Time & Space Function    4. Watch time & Bytes 

// --------------------------------------------------------------------------------------------------------
1.2 Characteristics of Algorithm 

Input (algorithm must take some input, 0 or more)
Output (algorithm must generate at least one ouput)
Definitness (Every statement should be ambigious, there cannot be statement that cannot be solved)
( - we cannot use for example value root -1 because we dont know its output too, program cannot either)
Finitness (solution must exist)
Effectivness (there shouldnt be any unnecesarry statements)

// --------------------------------------------------------------------------------------------------------
1.3 How to write an Algorithm 
- all algorithms are procedures to solve a problem 
Algorithm Swap(a,b)
{ "begin" 
    temp = a;
    a = b;
    b = temp;
} "end" 

How to analyze algorithm 
main criteria: 
1. Time (how much time is it taking)
- algorithm should be time efficient 
2. space (how much memory, space it will consume)
another criteria: 
3. data transfer, network consumption (because today everything is cloud-based)
4. Power comsumption (because of Mobile phones, Ipads and other mobile devices)
5. CPU register is algorithm consuming (how many resistors)

- all criteria depent on project
- every step in the algorithm takes 1 unit of time
{ "begin" 
    temp = a; ------ 1 
    a = b;    ------ 1 
    b = temp; ------ 1 
} "end" 
f(n) = 3 
- when we assign our statement it also is one unit of time 
x = 5 a + 6 b ------- 1 unit of time 

space calculation: 
a ------- 1
b ------- 1 
temp ----1 
S(n) = 3 words = words, because when we convert it into program we dont know if it is going to be 
int, float, double type 

// --------------------------------------------------------------------------------------------------------
1.4 Frequency control method

Addition array 
- we have array of size 5 
A [8 3 9 7 2]
A = array 
- lets analyze time of this algorithm 
- time of the algorithm can be known by assinging one unit of time for each statement 
- if each statement is repeating for some number of times , the frequency of statement 
will calculate and we will find the time taken by that algorithm 

Algorithm Sum(A,n)
{
  s=0 ----------------- 1 unit of time 
  for(i=0; i<n; i++) -- n+1                (i=0; i<n; i++)
    S=S+A[i] ---------- n                    1    n+1   n 
}                                           when n is 5
return s; ------------- 1                   i = 0, 0 < n 
                                            i = 1, 1 < n 
time complexity                             i = 2, 2 < n 
f(n) = 2n + 3 (we sum up numbers and n)     i = 3, 3 < n 
O(n)                                        i = 4, 4 < n 
                                            i = 5, 5 < n NOT 
space complexity                            which is n + 1 
- what are the variables used in here ? 
A --- n 
n --- 1 
s --- 1 
i --- 1 
S(n) = n + 3 
O(n)           (degree of this polynomial = O(n) = order of n)

----------------------------
Find the sum of two matrices 
matrices = 2 dimensional arrays nxn in this example 

Algorithm Add (A,B,n)
{
  for(i=0; i<n; i++) ------------ n + 1          (for loop time complexity)
  {                                              (whatever is inside this loop will execute x times)
    for(j=0; j<n; j++) ---------- n * (n + 1)    (we add n+1 times n because this is another for loop) 
    {
      c[i,j] = A[i,j] + B[i,j]; - n * n           (whatever is inside last one, will execute n times)
    }
  }
}

time complexity 
(n + 1 + n * (n + 1) + n * n)
f(n) = 2n2power + 2n + 1
O(n2power)
- we write n2squared only because of highest degree of polynomial

space complexity 
- what are the variables here, we are having: 
A -- n2power (matrices)
B -- n2power (matrices)
C -- n2power (matrices)
n -- 1 (word)
i -- 1 (word)
j -- 1 (word)
--------
s(n) = n2squared + n2squared + n2squared + 1 + 1 + 1
S(n) = 3n2power + 3 
- what is the highest degree of polynomial
O(n2power)

------------------------------
Multiplication of two matrices

Algorithm Multiply(A,B,n)
{
  for(i=0; i<n; i++)                --------- n + 1 
  {
    for(j=0; j<n; j++)              --------- (n + 1) * n 
    {
      c[i,j]=0;                     --------- n * n 
      for(k=0; k<n; k++)            --------- (n + 1) * n * n
      {
        c[i,j]=c[i,j]+A[i,k]*B[k,j]; -------- n * n * n
      }
    }
  }
}
- when we have first loop which is n + 1, we already know each statement will run at least for n times
- we have second for loop, we can assume every other statement will be n times 
- third loop means another n+1 on loop and last statement x times more

time complexity: 
= n + 1 + (n + 1) * n + n * n + (n + 1) * n * n + n * n * n
= n + 1 + n2squared + 1n + n2squared + 2n3power + 1n2squared 
= 3n2squared + 2n3power + 2n + 1  
      {
f(n) = 3n2squared + 2n3power + 2n + 1
- because of highest degree of polynomial we have n3power 
O(n3power)

space comlexity: 
A ---- n2squared 
B ---- n2squared
C ---- n2squared
n ---- 1 word 
j ---- 1 word
k ---- 1 word
i ---- 1 word
S(n) = 3n2squared + 4 
O(n2squared)

// --------------------------------------------------------------------------------------------------------
1.5 Time Complexity #1 

- increasing loop 
for(i=0; i<n; i++) --- n + 1 
{
  stmt; -------------- n 
}
Time Complexity: O(n)

- decreasing loop 
for(i=n; i>0; i--) --- n + 1 
{
  stmt; -------------- n 
}
Time Complexity: O(n)

- increasing loop by 2 
for(i=1; i<n; i=i+2) (we can get rid of upper n+1)
{
  stmt; -------------- n/2  
}
- but since this is polynomial n/2, what is the highest degree ?
- the highest degree of polynomial is n 
- which means this is also: 
Time Complexity: O(n)

- nested loops one inside another 
for(i=0; i<n; i++)    ----- n + 1 
{
  for(j=0; j<n; j++)  ----- (n + 1) x n 
  {
    stmt;             ----- n x n 
  }
}
Time complexity: O(n2squared)

- nested for loops one inside another with j<i in second for loop 
for(i=0; i<n; i++)    
{                           ////////////////////////
  for(j=0; j<i; j++)        |   i   |  j  | n time | 
  {                         |-------|-----|--------|  
    stmt; ------------------|   0   |  0X |    0   |
  }                         |-------|-----|--------|  
}                           |   1   | 0,1X|    1   |
1 + 2 + 3 + .... n =        |-------|-----|--------|
  n ( n + 1 )               |   2   |01,2X|    2   |
= -----------               |-------|-----|--------|
       2                    |   3   |0,1,2 3X| 3   |
f(n) = n2squared + 1 / 2    ////////////////////////          
- what is highest degree of polynomial ? 
O(n2squared)

- for loop where with P<=n 
P=0
for(i=1; P<=n; i++)
{
  P=P+i;
}
////////////////////////
|   i   |    P    |
|-------|---------|
|   1   | 0+1=1   |    
|-------|---------|
|   0   | 1+2=3   |
|-------|---------|
|   0   | 1+2+3+4 | 
|-------|---------|
|   K   |    K    | - this loop is going to execute for K times 
|-------|---------|
////////////////////////
- we assume that P > n the loop is stopped 
- as long as P is smaller or equal to n, the loop will execute 
- since P = k(k+1)
            ------
               2
- the condition is k(k+1)
                   ------ > n 
                      2 
- biggest part of this polynomial is k2squared > n 
- so if we exchange k with n it will be k > order of n 
- this loop will execute for order of n times

// ------------------------------
1.5.2 Time Complexity Examples #2 

- for loop with *2 in i++ 
- we can blindly say this will not execute for n times 
for(i=1; i<n; i=i*2)
{
  stmt; 
}
- we dont know n, so we dont know how many times 
i = 1 
i = i*2 = 1*2 = 2 
i = 2 
i = 2*2 = 2squared
i = 2squared = 4 
i = 2squared*2 = 2 to 3 power
i = 2 to 3 power 
i = 2 to 3 power*2 = 2 to 4 power
i = 2 to 4 power
i = 2 to 4 power*2 = 2 to 5 power
..........
- this will execute for 2 for k times 
2k 
- our rule: i < n will terminate until i < n
- assume i >= n 
- since i = 2 to power k 
2 power k >= n 
2k = n 
k = logn (in base 2 fromat)
- the statement will execute for order of:
Time compelxity: log n 
O(log n) in base 2 

----------------------------
for loop i++ vs for loop i*2

for(i=1; i<n; i=i*2)
{
  stmt; 
}
i = i * 2 * 2 * 2 * 2 .... = n 
2kpower = n 
k = logn (2)

for(i=1; i<n; i++)
{
  stmt; 
}
i = i+i+i+i+i ..... = n 
k = n 

- if we have a loop where value of i is going to  be multiplied than it is going to be : 
log n 
for(i=1; i<n; i=i*2)
{
  stmt; 
}
- if our output from log is decimal or float value, so we need to know if we want ot have C format value
- suppose n value = 8, 
n = 8 then 
i = 1, 2, 4, 8X = loop stops 
- we have 3 times loop run 
log 8 = 3
log 2 to power of 3 = 3log2
- since we have log in base 2 we can get rid of 2 and we are left with 3 

n = 10 then
i = 1, 2, 4, 8, 16X = loop stops here
- if we have log10, 10 is not exact number for power of 2, so we wont get exact number 
- we will recieve decimal value 
log 10 = 3.2 (this should be taken as seal value)
- which will correspont with our runtime which is 4 

- i value being fraction 
- dividing everytime starting from n 
for(i=n; i>=1; i=i/2)
{
  stmt;
}
- i value is starting with n, than n/2, next n2squared, than n2powerof3 .... 

i     n     n             n            n  
-- , --- , ---         , ---        , ---
n     2     2to2power     3to2power    n to k power

Assume i < 1 
 n 
--- < 1
 2 to power k 

 n 
--- = 1
 2 to power k 

n = 2 to power k 
k = logn 
O(log n)

------------------------
for(i=0; i*i<n; i++)
{
  stmt;
}
i*i<n
i*i>-n 
i to power of 2 = n 
i = square root of n 

------------------------
for(i=0; i<n; i++)
{
  stmt; --------- n 
}

- independent loops from one another

for(j=0; j<n; j++)
{
  stmt; ---------- n 
}
2n two independent loops together
O(n)

------------------------
- another example of two independent loops 
for(i=1; i<n; i*2)
{
  P++; ----------- log P 
}

for(j=1; j<P; j*2)
{
  stmt; ----------- log P 
}
- P = log n 
- and P is evaluted in upper loop 
O(log log n)

------------------------
for(i=0; i<n; i++) -------- n 
{
  for(j=0; j<n; j*2) ------ n * logn 
  {
  stmt; ------------------- n * logn 
  }
}
2nlogn+n
O(nlogn)

------------------------
for(i=0; i<n; i++) -------- O(n)
for(i=0; i<n; i=i+2) ------ n/2 O(n)
for(i=n; i>=1; i--) ------- O(n)
for(i=1; i<n; i*2) -------- O(log2n)
for(i=1; i<n; i*3) -------- O(log3n)
for(i=n; i>=1; i=i/2) ----- O(log2n)

// --------------------------------------------------------------------------------------------------------
1.5.3 Time Complexity of While and IF 

- Pascal language Syntax
for i = 1 to n do step 2    (1, 3, 5, 7, ...)
{
    stmt;
}
while(condition)         do                      repeat
{                        {                       {
    stmt;                   stmt;                   stmt; 
}                        } while (condition)     } until(condition);

- do while will execute as long as the condition is true 
- repeat until will execute until the condition is false 

// --------
- piece of code using while loop 
i = 0;    -------- 1 
while(i<n) ------- n+1
{
    stmt; -------- n 
    i++;  -------- n 
}
f(n) = 3n+2 
O(n)

- same code in C language
for(i=0; i<n; i++) ----- 1 + n+1 + n
{
    stmt; -------------- n
}
f(n)=3n+2
f(n)=2n+1
O(n)

---------------------
a = 1; 
while(a < b)
{
    stmt; 
    a = a * 2; 
}

a/1 
1 * 2 = 2
2 * 2 = 2to2power
2to2power * 2 = 2to3power
= 2 to k power 
- we dont know how many times is this going to happen

Terminate
a >= b 
a = 2tokpower
2tokpower >= b 
2tokpower = b 
k = log b 
O(log n)

- same code using for loop is: 
for(a=1; a<b; a=a*2)
{
    stmt; 
}

---------------
i = n;
while(i>1)
{
    stmt;
    i=i/2;
}
- is same as: 
for(i=n;i>1;i=i/2)
{
    stmt; 
}
----------------
i = 1;
k = 1; 
while(k<n)
{
  stmt; 
  k=k+1;
  i++;
}

i    k 
1    1
2    1+1=2
3    2+2
4    2+2+3
5    2+2+3+4
     m(m+1)
 m   ------
        2

k >= n
m(m+1) 
------ >= n 
   2
m to power 2 >= n 
m = square root of n 

O(square root of n)

- same loop written in for loop format: 
for(k=1; k<n; i++)
{
  stmt;
  k=k+1;
}

------------------
while(m!=n)
{
  if(m>n)
    m=m-n;
  else
    n=n-m; 
}

m = 6        m = 16
n = 3        n = 2 

m    n       m    n 
6    3       14   2       16/2
3    3       12   2       n/2 
0    3       10   2       O(n)
             8    2       min O(1)
             6    2
             4    2
             2    2

// --------------------------------------------------------------------------------------------------------
1.7 Types of functions 
O(1) = constant 

f(n) = 2  
f(n) = 5 
f(n) = 5000
f(n) = 1250 
f(n) = 1000000 
--------------
O(1)
- not dependent on the size of input, it is written as constant 

----------------------
O(log n) = Logarithmic 

f(n) = 2n+3
f(n) = 500n+700
f(n) = 2/5000 + 6 
- all of these are polynomials, and we write n
----------------------
O(n) = Linear 

----------------------
O(n2squared) = Quadratic 

----------------------
O(n3power) = Cubic

----------------------
O(2npower) = Exponential


------------------------------|
O(1) = constant               |
O(log n) = Logarithmic        |
O(n) = Linear                 |
O(n2squared) = Quadratic      |
O(n3power) = Cubic            |
O(2npower) = Exponential      |
------------------------------|

// --------------------------------------------------------------------------------------------------------
1.7.1 Compare Class of Functions 
1 < log n < square root of n < n < n log n < n2power < n3power < ntonpower

example: 

        log n       n       n2power         ntonpower 
          0         1          1                2
          1         2          4                4
          2         4         16               16
          3         8         64               256
          3.1....   9         81               512

n to power of 100 < 2 power of n 
- because n can be any number from 0 to infinity

COMMIT 1 COMMIT 1 COMMIT 1 COMMIT 1 COMMIT 1 COMMIT 1 COMMIT 1 COMMIT 1 COMMIT 1

// --------------------------------------------------------------------------------------------------------
1.8.1 Asymptotic Notations, Big Oh 
- mathematical background
- class of a function, we already know comparisons of functions 
- we need simple method for representing time complexity: 
Big-oh notation = UPPERBOUND of function 
big-omega       = LOWER BOUND of a function 
theta           = AVERAGE BOUND of a function 
- every function we represent is either: upperbound, lowerbound or averagebound 
- when we find time complexity of any function it will be one of these: 
1 < log n < square root of n < n < n log n < n2power < n3power < ntonpower
- if it is not one of these, than it will be multiple of them, otherwise we would not be able to graph them 

Example Big-Oh notation: 
The function f(n) = O(g(n)) if and only exist positive constants c and no
    such that f(n) <= c * g(n) for all n >= no
    
    sub-example: 
    f(n) = 2n+3                                    [10 = c, n = g(n)]
    2n+3 <= 10n n >= 1                      2n+3 <= 10n, n >= 1
    f(n) = O(n)                             [f(n)]       [for all n >= no]      
- g of n is n, there fore we can say f(n) = O(n)

    sub-example: 
    f(n) = 2n+3
    2n+3 <= 2n + 3n 
    2n+3 <= 5n   n >=1
    f(n) = O(n)
- if we put 1 there, it will be true
- if we put any other value in n, it will be greater

    sub-example: 
    f(n) = 2n+3
    2n+3 <= 2n2squared + 3n2squared
    2n+3 <= 5n2squared   n >=1
    f(n) = O(n2squared)
- the same function can also be O(n2squared)

- this f(n) = 2n + 3 belongs to this class, that means all functions
after n (n log n < n2power < n3power < ntonpower) BECOME UPPER BOUND 
- all the functions (1 < log n < square root of n) BECOME LOWER BOUND 
- n becomes AVERAGE BOUND 
                               |
1 < log n < square root of n < n < n log n < n2power < n3power < ntonpower

OMEGA NOTATION:
The function f(n) = OMEGA (g(n)) if and only exist positive constants c and no
  such that f(n) >= c * g(n) for all n >= no

  sub-example: 
  f(n) = 2n+3 
  2n+3>= 1*n     n>=1
  f(n)   c g(n)
  f(n) = OMEGA(n)

  sub-example: 
  f(n) = 2n+3 
  2n+3>= 1*log n     n>=1
  f(n)   c  g(n)
  f(n) = OMEGA(log n)

- useful one for OMEGA case is one which is closest = OMEGA(n)

THETA NOTATION: 
The function f(n) = OMEGA (g(n)) if and only exist positive constants c1, c2 and no
  such that c1 * g(n) <= f(n) <= c2*g(n) for all n >= no
  
  sub-example: 
  f(n) = 2n + 3 
  1 * n <= 2n+3 <= 5 * n 
  c1, g(n)  f(n)   c2, g(n)
  f(n) = THETA(n) 
- we cannot write inside THETA, any other thing except n, O(n)


1.8.2. Asymptotic Notations - Big Oh - Theta - Omega - PART 2

f(n) = 2n2power + 3n + 4
2n2power + 3n + 4 <= 2n2power + 5n2power + 4n2power
2n2power + 3n + 4 <= 9n2power     n>=1
f(n) = O(n2power)


f(n) = n2npower + 3n + 4 
2n2power + 3n + 4 >= 1 * n2power               OMEGA(n2power)
1 * n2power <= 2n2power + 3n + 4 <= 9n2power       O(n2power)


f(n) = n2power log n + n 
1 * n2power log n <= n2power log n <= 10 n2power log n 
O(n2power log n), OMEGA (n2power log n)
THETA (n2power log n)


f(n) = n! = n * (n-1) * (n-2) * ... * 3 * 2 * 1 
1 * 1 * * 1 * ... * 1 <= 1 * 2 * 3 ... * n < = n * n * n * n 
1 <= n! <= ntopowern
OMEGA(1), O(ntonpower)


f(n) = log n! 
log(1 * 1 * .... 1) <= log(1 * 2 * 3 ... * n) <= log(n * n * ... * n)
1 <= log n! <= log n2power 
OMEGA(1), O*|(n log n)

// --------------------------------------------------------------------------------------------------------
1.9 Properties of Asymptotic notations

General Properties
if f(n) is O(g(n)) then a * f(n) is O(g(n))
    sub example: 
    f(n) = 2n2power + 5 is O(n2power)
    then 7*f(n) = 7(2n2power + 5)
      = 14n2power + 35 is O(n2power)

Reflexive
if f(n) is given then f(n) = O(f(n))
    sub example: 
    f(n) = n2power   
    O(n2power)

Transitive 
if f(n) is O(g(n)) and g(n) is O(h(n))
then f(n) = O(h(n))
    sub example: 
    f(n) = n, g(n) = nto2power, h(n) = nto3power
    n is O(nto2power) and nto2power is O(n3power)
    then n is O(n3power)

Symmetric 
if f(n) is THETA(g(n)) then g(n) is THETA(f(n))
    sub example: 
    f(n) = n2power, g(n) = n2power
    f(n) = THETA(n2power)
    g(n) = THETA(n2power)

Transpose Symmetric
if f(n) = O(g(n)) then g(n) is OMEGA(f(n))
    sub example; 
    f(n) = n, g(n) = n2power
    then 
    n is O(n2power) 
    and 
    n2power is OMEGA(n)



if f(n) = O(g(n))
and f(n) = OMEGA(g(n))
g(n) <= f(n) <= g(n)
    f(n) = THETA(g(n))


if f(n) = O(g(n))
and d(n) = O(e(n))
then f(n) + d(n) = 
    sub example: 
    f(n) = n = O(n)
    d(n) = nto2power = O(nto2power)
    f(n) + d(n) = n + n2power = O(nto2power)

then f(n) + d(n) = O(max(g(n)))
    sub example: 
    f(n) = nto2power = O(n)
    d(n) = nto2power = O(nto2power)
    f(n) + d(n) = n2power + n = O(nto2power)

if f(n) = O(g(n))
and d(n) = O(e(n))
then f(n) * d(n) = O(g(n)*e(n))
       n      n2power

// --------------------------------------------------------------------------------------------------------
1.10.1 Comparison of functions 
n     nto2power          nto3power
2     2to2pwoer = 4      2to3power = 8 
3     3to2power = 9      3to3power = 27
4     4to2power = 16     4to3power = 64

nto2power         nto3power 
   Apply Log on Both sides 
log nto2power     log nto3power
log nto2power  <  log nto3power

-------------------------------------|
log ab = log a + log b               |
log a/b = log a - log b              |
log atopowerb = b log a              |
a topower(log b) = b topower(log a)  |
a topower b = n then b = log n       |
                            |        |
                            a        |
-------------------------------------|

f(n) = ntopower2 log n > g(n) = n(log n) to power of 10 
                      APPLY LOG 
log[n topower2 log n]           log[n(log n)to power of 10]
log n topower 2 + loglog n      log n + log (log n)
2logn + loglogn                 logn+ 10loglogn 

f(n) = 3n(n to power of (square root of n))            g(n) = 2 to power of (square root of n log n)
3 n to power (of square root of n)                     2 to power of (log n to power of (square root of n))
3 n to power (of square root of n)                     n to square root of n     
3 n to power (of square root of n)
2 n to power of 2

---------------------------------
1.10.2 Comparison of Functions #2 
f(n) = n to power of log n < g(n) = n to square root of n 
                      APPLY LOG 
log n to power of log n        log 2 to square root of n 
log n * log n                  square root of n log to power of 2 
log (to power of 2) n          square root of n = n to power of 1/2 
2 loglog n                     1/2 log n 


f(n) = 2 to power of log n     g(n) = n to power of square root of n 
log n * log to power of 2      square root of n, log n 
log n                          square root of n, log n 


f(n) = 2 to power of n         g(n) = 2 to power of 2n 
log 2 to power of n            log 2 to power of 2n 
n log 2                        2n log 2 

g 1 (n) = {n to power 3        n < 100  }
          {n to power 2        n >= 100 }
g 2 (n) = {n to power 2        n < 10000  }
          {n to power 3        n >= 10000 }

Exercise True / False 
1. (n+k) to power m = THETA(n to power m)          (n+3) to power of 2 = THETA(n to power 2)
2. 2 to power of n+1 = O(2 to power n)              2*2 to power of n 
3. 2 to power of 2n = O(2 to power of n)            4 to pwoer of n > 2 to power of n              
4. Square root(log n) = O(loglog n)
5. n to power of log n = O(2 to power of n)         log n * log n n 

// --------------------------------------------------------------------------------------------------------
1.11 Best, Worst and Average Case analysis 
1. Linear Search
2. Binary Search Tree 

1. Linear Search 

A 8 6 12 5 9 7 4 3 16 18
  0 1 2  3 4 5 6 7 8  9 
  key = 7 

Best case ---- searching key element present at first inolese
Best case Time ---- 1 O(1)
                B(n) = O(1)

Worst case ---- searching key at last index 
Worst case Time = n 
w(n) = n 
O(n)

Average case ---- all possible case time / no of cases
           1 + 2 + 3 + ... + n    n(n+1) / 2    n + 1 
Avg time = -------------------- = ---------- = -------
                     n                 n           2 

---------------|
B(n) = O(1)    |
w(n) = O(n)    |
A(n) = n+1 / 2 |
---------------|

B(n) = 1          w(n) = n 
B(n) = O(1)       w(n) = O(n)
B(n) = OMEGA(1)   w(n) = OMEGA(n)
B(n) = THETA(1)   w(n) = THETA(n)

2. Binary Search Tree 

           20 
         /    \
        10     30 
       /  \   /  \ 
       5  15 25  40 
Best case ---- search root ele 
Best case Time ---- B(n) = 1 
worst case ---- search for leaf ele
worst case Time ---- w(n) = log n 

40 -- 30 -- 25 -- 20 -- 15 -- 10 -- 5
-------------------------------------
                   n 
worst case Time - w(n) = h 
min w(n) = log n 
max w(n) = n 

// --------------------------------------------------------------------------------------------------------
1.12 Disjoint Sets Data Structure - Weighted Union and Collapsing Find 

Disjoint Sets 

1. Find 
2. Union 

S1 = {1, 2, 3, 4}
S2 = (5, 6, 7, 8)  

 u  v 
(4, 8)
(1, 5)

S1US2 = {1, 2, 3, 4, 5, 6, 7, 8}

  2 --- 3 
 /       \
1         4 
          
5         8
 \       / 
  6 --- 7


u = {1, 2, 3, 4, 5, 6, 7, 8}
S1 = {1, 2}
S2 = {3, 4}
S3 = {5, 6}
S4 = {7, 8}
S5 = {1, 2, 3, 4}                (2, 5)
S6 = {1, 2, 3, 4, 5, 6}          (1, 3)
S7 = {1, 2, 3, 4, 5, 6, 7, 8}    (6, 8)
                                 (5, 7)
1 ---- 3 
|      |
|      | 
2 ---- 4 
|
|
5 ---- 7
|      |
|      |
6 ---- 8  

u = {1, 2, 3, 4, 5, 6, 7, 8}
     1. 2. 3. 4. 5. 6. 7. 8. 

S1 = {1, 2} | S2 = {3, 4} | S3 = {5, 6} | S4 = {7, 8} | 
1. <-- 2.   | 3. <-- 4.   | 5. <-- 6.   | 7. <-- 8.

S6 = {1, 2, 3, 4, 5, 6}

    1 
   /|\
  2 | 5
    3  \ 
    |   6
    4

Parent = -1 -1 -1 -1 -1 -1 -1 -1 
          1  2  3  4  5  6  7  8

// --------------------------------------------------------------------------------------------------------
2. Divide and Conquer 

      P 
/   /  \  ... \ 
P1 P2  P3 ... Pk
|  |   |  ... |
S1 S2  S3 ... Sk
\  \   /  ... /
 \  \ /      /
      S

DAC(P)
{
    if(small(P))
    {
        S(P)
    }
    else 
    {
        divide P into P1, P2, p3, ... Pk 
        Apply DAC(P1), DAC(P2), ... 
        Combine(DAC(A)), DAC(P2),...
    }
}

// --------------------------------------------------------------------------------------------------------
2.1.1 Recurrence Relation (T(n)=T(n-1) + 1)

void Test(int n)
{
    if(n>0)
    {
        print("/d",n);
        Test(n-1);
    }
}
------
Test(3)

     Test(3)
     /      \
    -3      Test(2)
            /      \ 
          -2       Test(1)
                   /     \
                  -1     Test(0)
                            | 
                            x 
                        ---------
                        3 + 1 
                        f(n) = n + 1 call O(n)

- Recurrence method 

void Test(int n) ----- T(n)
{
    if(n>0)
    {
        print("/d",n); - 1
        Test(n-1); ----- T(n-1)
    }
}
T(n) = T(n-1) + 1 

T(n) = { 1          n = 0}
       { T(n-1)+1   n > 0}


- Substitution method 

void Test(int n) ----- T(n)
{
    if(n>0)
    {
        print("/d",n); - 1
        Test(n-1); ----- T(n-1)
    }
}

T(n) = { 1          n = 0}
       { T(n-1)+1   n > 0}

          |--------------------------------------\
          |                                      |
T(n) = T(n-1) + 1           T(n) = T(n-1) + 1    |  
                            T(n-1) = T(n-2) + 1--|
substitute T(n-1)           T(n-2) = T(n-3) + 1
T(n) = [T(n-2) + 1] + 1            |
T(n) = T(n-2) + 2 <----------------|
T(n) = [T(n-3) + 1] + 2
T(n) = T(n-3) + 3 
.... continues for k times 
T(n) = T(n-k) + k

T(n) = T(n-k) + k
Assume n - k = 0
... n = k 
T(n) = T(n-n) + n 
T(n) = T(0) + n 
T(n) = 1 + n 
O(n)

// --------------------------------------------------------------------------------------------------------
