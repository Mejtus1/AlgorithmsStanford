// --------------------------------------------------------------------------------------------------------
1. Introduction to Algorithms 
- algorithm is a step by step procedure of solving computational problem 
- program is also a step by step procedure of solving a problem 
- SDLC = software development lifecycle 
Algorithm                     Program 
Deisgn phase of SDLC          Implementation phase of SDLC 
Domain knowledge              Programmer (programmer can also have domain knowledge)
any language                  programming language 
(or mathematical notation)
Hardware/Software/OS          H/S/OS dependent 
idependent 
Analyze                       Testing 

// --------------------------------------------------------------------------------------------------------
1.1 Priori analysis, Postpriori testing 

Priori Analysis             Posteriori Testing
1. Algorithm                1. Program
2. Independent Language     2. Language dependent 
3. Hardware Independent     3. Hardware dependent 
4. Time & Space Function    4. Watch time & Bytes 

// --------------------------------------------------------------------------------------------------------
1.2 Characteristics of Algorithm 

Input (algorithm must take some input, 0 or more)
Output (algorithm must generate at least one ouput)
Definitness (Every statement should be ambigious, there cannot be statement that cannot be solved)
( - we cannot use for example value root -1 because we dont know its output too, program cannot either)
Finitness (solution must exist)
Effectivness (there shouldnt be any unnecesarry statements)

// --------------------------------------------------------------------------------------------------------
1.3 How to write an Algorithm 
- all algorithms are procedures to solve a problem 
Algorithm Swap(a,b)
{ "begin" 
    temp = a;
    a = b;
    b = temp;
} "end" 

How to analyze algorithm 
main criteria: 
1. Time (how much time is it taking)
- algorithm should be time efficient 
2. space (how much memory, space it will consume)
another criteria: 
3. data transfer, network consumption (because today everything is cloud-based)
4. Power comsumption (because of Mobile phones, Ipads and other mobile devices)
5. CPU register is algorithm consuming (how many resistors)

- all criteria depent on project
- every step in the algorithm takes 1 unit of time
{ "begin" 
    temp = a; ------ 1 
    a = b;    ------ 1 
    b = temp; ------ 1 
} "end" 
f(n) = 3 
- when we assign our statement it also is one unit of time 
x = 5 a + 6 b ------- 1 unit of time 

space calculation: 
a ------- 1
b ------- 1 
temp ----1 
S(n) = 3 words = words, because when we convert it into program we dont know if it is going to be 
int, float, double type 

// --------------------------------------------------------------------------------------------------------
1.4 Frequency control method

Addition array 
- we have array of size 5 
A [8 3 9 7 2]
A = array 
- lets analyze time of this algorithm 
- time of the algorithm can be known by assinging one unit of time for each statement 
- if each statement is repeating for some number of times , the frequency of statement 
will calculate and we will find the time taken by that algorithm 

Algorithm Sum(A,n)
{
  s=0 ----------------- 1 unit of time 
  for(i=0; i<n; i++) -- n+1                (i=0; i<n; i++)
    S=S+A[i] ---------- n                    1    n+1   n 
}                                           when n is 5
return s; ------------- 1                   i = 0, 0 < n 
                                            i = 1, 1 < n 
time complexity                             i = 2, 2 < n 
f(n) = 2n + 3 (we sum up numbers and n)     i = 3, 3 < n 
O(n)                                        i = 4, 4 < n 
                                            i = 5, 5 < n NOT 
space complexity                            which is n + 1 
- what are the variables used in here ? 
A --- n 
n --- 1 
s --- 1 
i --- 1 
S(n) = n + 3 
O(n)           (degree of this polynomial = O(n) = order of n)

----------------------------
Find the sum of two matrices 
matrices = 2 dimensional arrays nxn in this example 

Algorithm Add (A,B,n)
{
  for(i=0; i<n; i++) ------------ n + 1          (for loop time complexity)
  {                                              (whatever is inside this loop will execute x times)
    for(j=0; j<n; j++) ---------- n * (n + 1)    (we add n+1 times n because this is another for loop) 
    {
      c[i,j] = A[i,j] + B[i,j]; - n * n           (whatever is inside last one, will execute n times)
    }
  }
}

time complexity 
(n + 1 + n * (n + 1) + n * n)
f(n) = 2n2power + 2n + 1
O(n2power)
- we write n2squared only because of highest degree of polynomial

space complexity 
- what are the variables here, we are having: 
A -- n2power (matrices)
B -- n2power (matrices)
C -- n2power (matrices)
n -- 1 (word)
i -- 1 (word)
j -- 1 (word)
--------
s(n) = n2squared + n2squared + n2squared + 1 + 1 + 1
S(n) = 3n2power + 3 
- what is the highest degree of polynomial
O(n2power)

------------------------------
Multiplication of two matrices

Algorithm Multiply(A,B,n)
{
  for(i=0; i<n; i++)                --------- n + 1 
  {
    for(j=0; j<n; j++)              --------- (n + 1) * n 
    {
      c[i,j]=0;                     --------- n * n 
      for(k=0; k<n; k++)            --------- (n + 1) * n * n
      {
        c[i,j]=c[i,j]+A[i,k]*B[k,j]; -------- n * n * n
      }
    }
  }
}
- when we have first loop which is n + 1, we already know each statement will run at least for n times
- we have second for loop, we can assume every other statement will be n times 
- third loop means another n+1 on loop and last statement x times more

time complexity: 
= n + 1 + (n + 1) * n + n * n + (n + 1) * n * n + n * n * n
= n + 1 + n2squared + 1n + n2squared + 2n3power + 1n2squared 
= 3n2squared + 2n3power + 2n + 1  
      {
f(n) = 3n2squared + 2n3power + 2n + 1
- because of highest degree of polynomial we have n3power 
O(n3power)

space comlexity: 
A ---- n2squared 
B ---- n2squared
C ---- n2squared
n ---- 1 word 
j ---- 1 word
k ---- 1 word
i ---- 1 word
S(n) = 3n2squared + 4 
O(n2squared)

// --------------------------------------------------------------------------------------------------------
1.5 Time Complexity #1 

- increasing loop 
for(i=0; i<n; i++) --- n + 1 
{
  stmt; -------------- n 
}
Time Complexity: O(n)

- decreasing loop 
for(i=n; i>0; i--) --- n + 1 
{
  stmt; -------------- n 
}
Time Complexity: O(n)

- increasing loop by 2 
for(i=1; i<n; i=i+2) (we can get rid of upper n+1)
{
  stmt; -------------- n/2  
}
- but since this is polynomial n/2, what is the highest degree ?
- the highest degree of polynomial is n 
- which means this is also: 
Time Complexity: O(n)

- nested loops one inside another 
for(i=0; i<n; i++)    ----- n + 1 
{
  for(j=0; j<n; j++)  ----- (n + 1) x n 
  {
    stmt;             ----- n x n 
  }
}
Time complexity: O(n2squared)

- nested for loops one inside another with j<i in second for loop 
for(i=0; i<n; i++)    
{                           ////////////////////////
  for(j=0; j<i; j++)        |   i   |  j  | n time | 
  {                         |-------|-----|--------|  
    stmt; ------------------|   0   |  0X |    0   |
  }                         |-------|-----|--------|  
}                           |   1   | 0,1X|    1   |
1 + 2 + 3 + .... n =        |-------|-----|--------|
  n ( n + 1 )               |   2   |01,2X|    2   |
= -----------               |-------|-----|--------|
       2                    |   3   |0,1,2 3X| 3   |
f(n) = n2squared + 1 / 2    ////////////////////////          
- what is highest degree of polynomial ? 
O(n2squared)

- for loop where with P<=n 
P=0
for(i=1; P<=n; i++)
{
  P=P+i;
}
////////////////////////
|   i   |    P    |
|-------|---------|
|   1   | 0+1=1   |    
|-------|---------|
|   0   | 1+2=3   |
|-------|---------|
|   0   | 1+2+3+4 | 
|-------|---------|
|   K   |    K    | - this loop is going to execute for K times 
|-------|---------|
////////////////////////
- we assume that P > n the loop is stopped 
- as long as P is smaller or equal to n, the loop will execute 
- since P = k(k+1)
            ------
               2
- the condition is k(k+1)
                   ------ > n 
                      2 
- biggest part of this polynomial is k2squared > n 
- so if we exchange k with n it will be k > order of n 
- this loop will execute for order of n times

// ------------------------------
1.5.2 Time Complexity Examples #2 

- for loop with *2 in i++ 
- we can blindly say this will not execute for n times 
for(i=1; i<n; i=i*2)
{
  stmt; 
}
- we dont know n, so we dont know how many times 
i = 1 
i = i*2 = 1*2 = 2 
i = 2 
i = 2*2 = 2squared
i = 2squared = 4 
i = 2squared*2 = 2 to 3 power
i = 2 to 3 power 
i = 2 to 3 power*2 = 2 to 4 power
i = 2 to 4 power
i = 2 to 4 power*2 = 2 to 5 power
..........
- this will execute for 2 for k times 
2k 
- our rule: i < n will terminate until i < n
- assume i >= n 
- since i = 2 to power k 
2 power k >= n 
2k = n 
k = logn (in base 2 fromat)
- the statement will execute for order of:
Time compelxity: log n 
O(log n) in base 2 

----------------------------
for loop i++ vs for loop i*2

for(i=1; i<n; i=i*2)
{
  stmt; 
}
i = i * 2 * 2 * 2 * 2 .... = n 
2kpower = n 
k = logn (2)

for(i=1; i<n; i++)
{
  stmt; 
}
i = i+i+i+i+i ..... = n 
k = n 

- if we have a loop where value of i is going to  be multiplied than it is going to be : 
log n 
for(i=1; i<n; i=i*2)
{
  stmt; 
}
- if our output from log is decimal or float value, so we need to know if we want ot have C format value
- suppose n value = 8, 
n = 8 then 
i = 1, 2, 4, 8X = loop stops 
- we have 3 times loop run 
log 8 = 3
log 2 to power of 3 = 3log2
- since we have log in base 2 we can get rid of 2 and we are left with 3 

n = 10 then
i = 1, 2, 4, 8, 16X = loop stops here
- if we have log10, 10 is not exact number for power of 2, so we wont get exact number 
- we will recieve decimal value 
log 10 = 3.2 (this should be taken as seal value)
- which will correspont with our runtime which is 4 

- i value being fraction 
- dividing everytime starting from n 
for(i=n; i>=1; i=i/2)
{
  stmt;
}
- i value is starting with n, than n/2, next n2squared, than n2powerof3 .... 

i     n     n             n            n  
-- , --- , ---         , ---        , ---
n     2     2to2power     3to2power    n to k power

Assume i < 1 
 n 
--- < 1
 2 to power k 

 n 
--- = 1
 2 to power k 

n = 2 to power k 
k = logn 
O(log n)

------------------------
for(i=0; i*i<n; i++)
{
  stmt;
}
i*i<n
i*i>-n 
i to power of 2 = n 
i = square root of n 

------------------------
for(i=0; i<n; i++)
{
  stmt; --------- n 
}

- independent loops from one another

for(j=0; j<n; j++)
{
  stmt; ---------- n 
}
2n two independent loops together
O(n)

------------------------
- another example of two independent loops 
for(i=1; i<n; i*2)
{
  P++; ----------- log P 
}

for(j=1; j<P; j*2)
{
  stmt; ----------- log P 
}
- P = log n 
- and P is evaluted in upper loop 
O(log log n)

------------------------
for(i=0; i<n; i++) -------- n 
{
  for(j=0; j<n; j*2) ------ n * logn 
  {
  stmt; ------------------- n * logn 
  }
}
2nlogn+n
O(nlogn)

------------------------
for(i=0; i<n; i++) -------- O(n)
for(i=0; i<n; i=i+2) ------ n/2 O(n)
for(i=n; i>=1; i--) ------- O(n)
for(i=1; i<n; i*2) -------- O(log2n)
for(i=1; i<n; i*3) -------- O(log3n)
for(i=n; i>=1; i=i/2) ----- O(log2n)

// --------------------------------------------------------------------------------------------------------
1.5.3 Time Complexity of While and IF 

- Pascal language Syntax
for i = 1 to n do step 2    (1, 3, 5, 7, ...)
{
    stmt;
}
while(condition)         do                      repeat
{                        {                       {
    stmt;                   stmt;                   stmt; 
}                        } while (condition)     } until(condition);

- do while will execute as long as the condition is true 
- repeat until will execute until the condition is false 

// --------
- piece of code using while loop 
i = 0;    -------- 1 
while(i<n) ------- n+1
{
    stmt; -------- n 
    i++;  -------- n 
}
f(n) = 3n+2 
O(n)

- same code in C language
for(i=0; i<n; i++) ----- 1 + n+1 + n
{
    stmt; -------------- n
}
f(n)=3n+2
f(n)=2n+1
O(n)

---------------------
a = 1; 
while(a < b)
{
    stmt; 
    a = a * 2; 
}

a/1 
1 * 2 = 2
2 * 2 = 2to2power
2to2power * 2 = 2to3power
= 2 to k power 
- we dont know how many times is this going to happen

Terminate
a >= b 
a = 2tokpower
2tokpower >= b 
2tokpower = b 
k = log b 
O(log n)

- same code using for loop is: 
for(a=1; a<b; a=a*2)
{
    stmt; 
}

---------------
i = n;
while(i>1)
{
    stmt;
    i=i/2;
}
- is same as: 
for(i=n;i>1;i=i/2)
{
    stmt; 
}
----------------
i = 1;
k = 1; 
while(k<n)
{
  stmt; 
  k=k+1;
  i++;
}

i    k 
1    1
2    1+1=2
3    2+2
4    2+2+3
5    2+2+3+4
     m(m+1)
 m   ------
        2

k >= n
m(m+1) 
------ >= n 
   2
m to power 2 >= n 
m = square root of n 

O(square root of n)

- same loop written in for loop format: 
for(k=1; k<n; i++)
{
  stmt;
  k=k+1;
}

------------------
while(m!=n)
{
  if(m>n)
    m=m-n;
  else
    n=n-m; 
}

m = 6        m = 16
n = 3        n = 2 

m    n       m    n 
6    3       14   2       16/2
3    3       12   2       n/2 
0    3       10   2       O(n)
             8    2       min O(1)
             6    2
             4    2
             2    2

// --------------------------------------------------------------------------------------------------------
1.7 Types of functions 
O(1) = constant 

f(n) = 2  
f(n) = 5 
f(n) = 5000
f(n) = 1250 
f(n) = 1000000 
--------------
O(1)
- not dependent on the size of input, it is written as constant 

----------------------
O(log n) = Logarithmic 

f(n) = 2n+3
f(n) = 500n+700
f(n) = 2/5000 + 6 
- all of these are polynomials, and we write n
----------------------
O(n) = Linear 

----------------------
O(n2squared) = Quadratic 

----------------------
O(n3power) = Cubic

----------------------
O(2npower) = Exponential


------------------------------|
O(1) = constant               |
O(log n) = Logarithmic        |
O(n) = Linear                 |
O(n2squared) = Quadratic      |
O(n3power) = Cubic            |
O(2npower) = Exponential      |
------------------------------|

// --------------------------------------------------------------------------------------------------------
1.7.1 Compare Class of Functions 
1 < log n < square root of n < n < n log n < n2power < n3power < ntonpower

example: 

        log n       n       n2power         ntonpower 
          0         1          1                2
          1         2          4                4
          2         4         16               16
          3         8         64               256
          3.1....   9         81               512

n to power of 100 < 2 power of n 
- because n can be any number from 0 to infinity

COMMIT 1 COMMIT 1 COMMIT 1 COMMIT 1 COMMIT 1 COMMIT 1 COMMIT 1 COMMIT 1 COMMIT 1

// --------------------------------------------------------------------------------------------------------
1.8.1 Asymptotic Notations, Big Oh 
- mathematical background
- class of a function, we already know comparisons of functions 
- we need simple method for representing time complexity: 
Big-oh notation = UPPERBOUND of function 
big-omega       = LOWER BOUND of a function 
theta           = AVERAGE BOUND of a function 
- every function we represent is either: upperbound, lowerbound or averagebound 
- when we find time complexity of any function it will be one of these: 
1 < log n < square root of n < n < n log n < n2power < n3power < ntonpower
- if it is not one of these, than it will be multiple of them, otherwise we would not be able to graph them 

Example Big-Oh notation: 
The function f(n) = O(g(n)) if and only exist positive constants c and no
    such that f(n) <= c * g(n) for all n >= no
    
    sub-example: 
    f(n) = 2n+3                                    [10 = c, n = g(n)]
    2n+3 <= 10n n >= 1                      2n+3 <= 10n, n >= 1
    f(n) = O(n)                             [f(n)]       [for all n >= no]      
- g of n is n, there fore we can say f(n) = O(n)

    sub-example: 
    f(n) = 2n+3
    2n+3 <= 2n + 3n 
    2n+3 <= 5n   n >=1
    f(n) = O(n)
- if we put 1 there, it will be true
- if we put any other value in n, it will be greater

    sub-example: 
    f(n) = 2n+3
    2n+3 <= 2n2squared + 3n2squared
    2n+3 <= 5n2squared   n >=1
    f(n) = O(n2squared)
- the same function can also be O(n2squared)

- this f(n) = 2n + 3 belongs to this class, that means all functions
after n (n log n < n2power < n3power < ntonpower) BECOME UPPER BOUND 
- all the functions (1 < log n < square root of n) BECOME LOWER BOUND 
- n becomes AVERAGE BOUND 
                               |
1 < log n < square root of n < n < n log n < n2power < n3power < ntonpower

OMEGA NOTATION:
The function f(n) = OMEGA (g(n)) if and only exist positive constants c and no
  such that f(n) >= c * g(n) for all n >= no

  sub-example: 
  f(n) = 2n+3 
  2n+3>= 1*n     n>=1
  f(n)   c g(n)
  f(n) = OMEGA(n)

  sub-example: 
  f(n) = 2n+3 
  2n+3>= 1*log n     n>=1
  f(n)   c  g(n)
  f(n) = OMEGA(log n)

- useful one for OMEGA case is one which is closest = OMEGA(n)

THETA NOTATION: 
The function f(n) = OMEGA (g(n)) if and only exist positive constants c1, c2 and no
  such that c1 * g(n) <= f(n) <= c2*g(n) for all n >= no
  
  sub-example: 
  f(n) = 2n + 3 
  1 * n <= 2n+3 <= 5 * n 
  c1, g(n)  f(n)   c2, g(n)
  f(n) = THETA(n) 
- we cannot write inside THETA, any other thing except n, O(n)


1.8.2. Asymptotic Notations - Big Oh - Theta - Omega - PART 2

f(n) = 2n2power + 3n + 4
2n2power + 3n + 4 <= 2n2power + 5n2power + 4n2power
2n2power + 3n + 4 <= 9n2power     n>=1
f(n) = O(n2power)


f(n) = n2npower + 3n + 4 
2n2power + 3n + 4 >= 1 * n2power               OMEGA(n2power)
1 * n2power <= 2n2power + 3n + 4 <= 9n2power       O(n2power)


f(n) = n2power log n + n 
1 * n2power log n <= n2power log n <= 10 n2power log n 
O(n2power log n), OMEGA (n2power log n)
THETA (n2power log n)


f(n) = n! = n * (n-1) * (n-2) * ... * 3 * 2 * 1 
1 * 1 * * 1 * ... * 1 <= 1 * 2 * 3 ... * n < = n * n * n * n 
1 <= n! <= ntopowern
OMEGA(1), O(ntonpower)


f(n) = log n! 
log(1 * 1 * .... 1) <= log(1 * 2 * 3 ... * n) <= log(n * n * ... * n)
1 <= log n! <= log n2power 
OMEGA(1), O*|(n log n)

// --------------------------------------------------------------------------------------------------------
