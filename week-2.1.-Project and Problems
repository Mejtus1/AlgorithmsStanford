// --------------------------------------------------------------------------------------
Big Oh notation basic examples 

Example 1: 
- these examples serve as sanity check of what Big O is doing what its intendet purpose is 
                     k 
Claim: if T(n) = a  a  + ...... + a, n + n    then 
          k       k                       o
T(n) = O(n )
Proof: 
- how does one show that one function is bigger than other = whole key is to find a pair of constants
- choose no = 1 and c = |ak| + |ak1| + ... + |a1| + |a0| 
We need to show that for all n >= 1, T(n) = c * n(to pwoer of k)
We have for every n >= 1, 
T(n) <= |ak|n(to pwoer of k) + ... + |a1|n + |a0|
- common power of n, we replace all of these n to n(to power of k)
     <= |ak|n(to pwoer of k) + ... + |a1|n(to power of k) + |a0|n(to power of k)
     <= c * n(to power of k)
- we have proven that T(n) = O(n(to power of k))

Example 2: 
Claim: for every K >= 1, n(to power of k) is not O(n(to power of k-1))
Proof: by contradiction(we astablish what is actually false)
- suppose n(to power of k) = O(n(to k power - 1))
- then 2 constants c1n0 > 0, such that n(to pwoer of k) <= c * n(to power of k-1), for all n >= n0 
Put then can ceiling n(to pwoer of k-1) from both sides 
n <= c, for all n >= n0 
False statement is clearly false contradiction

// --------------------------------------------------------------------------------------
Big Omega, Theta 

Omega = Ω
Theta = Θ

- Omega notation, denoted as Ω, is a way to describe lower bound of time or space complexity of algorith, 
- similar to big O notation, but instead of focusing on upper bound or worst-case scenario, omega notation focuses on lower bound or best-case scenario
- when is said that function T(N) is Ω(F(N)), it means that for sufficiently large inputs 
(N), T(N) will always be greater than or equal to constant multiple of F(N)
- in simpler terms, T(N) grows at least as fast as F(N) for large enough inputs

Omega Notation 
Definition: T(n) = Ω(f(n)) 
if and only if constants c1n0 such that
T(n) >= c * f(n) for all n >= n0 

Theta Notation 
- theta notation tells us that behavior of T(N) is tightly bound by behavior of F(N) as N becomes large 
- it signifies equivalence or balance in growth rates between the two functions
- denoted as Θ, is mathematical notation used in analysis of algorithms to describe growth rate of functions
- it represents tight bound between two functions, indicating that one function grows at same rate as other, up to constant factors, for sufficiently large inputs
- when is said T(N) is Θ(F(N)), it means that 
- T(N) grows at same rate as F(N), neither faster nor slower, for sufficiently large values of N,
because theta notation indicates tight bound between two functions

- describing it as T(N) being "sandwiched" between two multiples of F(N) reinforces this idea
- it means that T(N) consistently falls between two constant multiples of F(N) as N becomes large
- this sandwiching implies equality, indicating that behavior of T(N) closely mirrors that of F(N) in terms of growth rate

Definition: T(n) = Θ(f(n)) if and only if 
T(n) = O(f(n)) and T(n) = Ω(f(n))
Equivalent: constants c1, c2, n0 such that
c1f(n) <= T(n) <= c2f(n)
for all n>n0 

Exercise 1: 
Let T(n) = 1/2n(to power of 2) + 3n. Which of following staements are true ? 
a) T(n) = O(n)
b) T(n) = Ω(n)
c) T(n) = Θ(n(to power of 2))
d) T(n) = O(n(to power of 3))

b), c), d) are true 
b) [n0 = 1, c = 1/2]
c) [n0 = 1, c1 = 1/2, c2 = 4]
d) [n0 = 1, c = 4]

Exercise 2: 
Claim: 2(to power of n + 10) = O(2(to power of n))
Proof: 
- we need to proove that there exists 2 constants c1 n0, such that for all positive n >= n0 
2(to power of n + 10) <= c * 2(to power of n)
Note: 2(to power of n+10) = 2(to power of 10) * 2(to power of n)
= (1024) * 2(to power of n)             
                                      [c * 2(to power of n) = 1024 * 2(to power of n)]
So: 
- if we choose c = 1024, n0 = 1 then OUR ASSUMPTION HOLDS 

Exercise 3: 
Claim: 2(to power of 10n) is not O(2(to power of 2))
Proof: by contradiction. If 2(to power of 10n) = O(2(to power of n)), then 
constants c1 n0 > 0 such that 2(to power of 10n) <= c * 2(to power of n)    for all numbers
both sides divided by 2(to the n power): 
2(to power of 9n) <= c for all numbers n >= n0
- certainly false 

Exercise 4: 
Claim: for every pair of (positive) functinos f(n), g(n), 
max[f,g] = O(f(n)+ g(n))
- maximum of two functinos is a theta of the sum of TWO FUNTIN2(to power of n 

Proof: [max{f,g} = O(f(n) + g(n))]
For every n, we have
    max{f(n),g(n)} <= f(n) + g(n)
and 
    2max{f(n),g(n)} >=  f(n) + g(n)
    /2 
    max{f(n),g(n)} >= 1/2(f(n) + g(n))
thus: 1/2(f(n) + g(n)) <= max{f(n),g(n)} <= f(n) + g(n)
for all n >= 1 

=> max{f,g} = O(f(n) + g(n)) [where n0 = 1, c1 = 1/2, c2 = 1]
